{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56a36cd2-33da-4281-b165-1e0bad1afe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"MinIOSparkJob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5202f7-aded-43c9-8620-2d7acc6934f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/04 14:33:54 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# start spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('parquet-load') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465909fd-fcc4-4e84-b392-500a101b0276",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.app.id: local-1733322832494\n",
      "spark.eventLog.enabled: true\n",
      "spark.app.startTime: 1733322832075\n",
      "spark.history.fs.logDirectory: /home/iceberg/spark-events\n",
      "spark.sql.warehouse.dir: file:/home/iceberg/notebooks/notebooks/spark-warehouse\n",
      "spark.sql.catalog.demo.s3.endpoint: http://minio:9000\n",
      "spark.eventLog.dir: /home/iceberg/spark-events\n",
      "spark.serializer.objectStreamReset: 100\n",
      "spark.master: local[*]\n",
      "spark.submit.deployMode: client\n",
      "spark.driver.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.sql.catalogImplementation: in-memory\n",
      "spark.driver.port: 34433\n",
      "spark.sql.catalog.demo.io-impl: org.apache.iceberg.aws.s3.S3FileIO\n",
      "spark.sql.catalog.demo.warehouse: s3://warehouse/wh/\n",
      "spark.sql.catalog.demo.type: hive\n",
      "spark.executor.id: driver\n",
      "spark.app.name: PySparkShell\n",
      "spark.sql.extensions: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\n",
      "spark.driver.host: ea1f8f1621a8\n",
      "spark.rdd.compress: True\n",
      "spark.executor.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.sql.catalog.demo: org.apache.iceberg.spark.SparkCatalog\n",
      "spark.sql.defaultCatalog: demo\n",
      "spark.submit.pyFiles: \n",
      "spark.sql.catalog.demo.uri: http://metastore:9083\n",
      "spark.ui.showConsoleProgress: true\n",
      "spark.app.submitTime: 1733322832000\n"
     ]
    }
   ],
   "source": [
    "for key, value in spark.sparkContext.getConf().getAll():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedf28be-3988-4c24-9e70-e485b78d4ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding iceberg configs\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .set(\"spark.sql.extensions\", \n",
    "         \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") # Use Iceberg with Spark\n",
    "    .set(\"spark.sql.catalog.demo\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .set(\"spark.sql.catalog.demo.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "    .set(\"spark.sql.catalog.demo.warehouse\", \"s3a://warehouse\")\n",
    "    .set(\"spark.sql.catalog.demo.s3.endpoint\", \"http://minio:9000\")\n",
    "    .set(\"spark.sql.defaultCatalog\", \"demo\") # Name of the Iceberg catalog\n",
    "    .set(\"spark.sql.catalogImplementation\", \"in-memory\")\n",
    "    .set(\"spark.sql.catalog.data.type\", \"hive\") # Iceberg catalog type\n",
    "    .set(\"spark.executor.heartbeatInterval\", \"300000\")\n",
    "    .set(\"spark.network.timeout\", \"400000\")\n",
    "    .set(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.2,aws-java-sdk-bundle:1.12.756\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d84e03-31e3-4724-9eee-e6c4e94029b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add confs\n",
    "sc = spark.sparkContext\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"admin\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"password\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.aws.credentials.provider\", \n",
    "                                   \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea7e55c-f516-44a6-a640-cc4d350041d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/04 14:34:14 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b7cc662-cdfe-4c84-9a4e-e95989ad5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable below line to see INFO logs\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c510aab-bc1d-45a0-ac31-16e64e5cb92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(spark_context: SparkContext):\n",
    "    spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", os.getenv(\"AWS_ACCESS_KEY_ID\", \"admin\"))\n",
    "    spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\",\n",
    "                                                 os.getenv(\"AWS_SECRET_ACCESS_KEY\", \"password\"))\n",
    "    spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", os.getenv(\"ENDPOINT\", \"http://minio:9000\"))\n",
    "    spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"true\")\n",
    "    spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
    "    spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.attempts.maximum\", \"1\")\n",
    "    spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.connection.establish.timeout\", \"5000\")\n",
    "    spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.connection.timeout\", \"10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbf95008-20a9-4bbd-a820-8891d83871cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_config(spark.sparkContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9381b19b-e76b-4e34-a990-b299de9d3c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://metastore:9083'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.catalog.demo.uri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "905e3382-e3d3-42a7-a4ac-439a5ebd5061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925baf0e-0107-4bc9-8049-d02c054d41ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN default\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1736f834-18a7-44e7-b90e-a6db1fc48739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, LongType, DoubleType, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e704f6a-6c06-4fc3-a394-bb4e430ce581",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"fn\",StringType(),True), \\\n",
    "    StructField(\"mid\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9038c68-a446-4bca-8a20-14db4b541e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fn: string (nullable = true)\n",
      " |-- mid: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8c9ee30-6853-4375-a594-56d089851ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------+-----+------+------+\n",
      "|     fn| mid|lastname|   id|gender|salary|\n",
      "+-------+----+--------+-----+------+------+\n",
      "|  James|    |   Smith|36636|     M|  3000|\n",
      "|Michael|Rose|        |40288|     M|  4000|\n",
      "| Robert|    |Williams|42114|     M|  4000|\n",
      "|  Maria|Anne|   Jones|39192|     F|  4000|\n",
      "|    Jen|Mary|   Brown|     |     F|    -1|\n",
      "+-------+----+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6845ce44-7249-4df4-b7af-b68fabe40541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"parquet\") \\\n",
    "    .save(\"s3a://warehouse/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007ea0de-5da0-4179-8a72-771ce9582614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"\n",
    "#     CREATE TABLE IF NOT EXISTS demo.default.my_iceberg (\n",
    "#         fn STRING,\n",
    "#         mid STRING,\n",
    "#         lastname STRING,\n",
    "#         id STRING,\n",
    "#         gender STRING,\n",
    "#         salary INT\n",
    "#     )\n",
    "#     USING iceberg\n",
    "#     PARTITIONED BY (id)\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2afc271c-e231-4148-9920-128493e64a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.writeTo(\"default.my_iceberg\").createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "815d8469-a36d-4d4b-a662-0b33abbb2705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+\n",
      "|namespace| tableName|isTemporary|\n",
      "+---------+----------+-----------+\n",
      "|  default|my_iceberg|      false|\n",
      "+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN default\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8387b2cb-95b8-481a-ae0d-2b2b23b235b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>fn</th>\n",
       "            <th>mid</th>\n",
       "            <th>lastname</th>\n",
       "            <th>id</th>\n",
       "            <th>gender</th>\n",
       "            <th>salary</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>James</td>\n",
       "            <td></td>\n",
       "            <td>Smith</td>\n",
       "            <td>36636</td>\n",
       "            <td>M</td>\n",
       "            <td>3000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Michael</td>\n",
       "            <td>Rose</td>\n",
       "            <td></td>\n",
       "            <td>40288</td>\n",
       "            <td>M</td>\n",
       "            <td>4000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Robert</td>\n",
       "            <td></td>\n",
       "            <td>Williams</td>\n",
       "            <td>42114</td>\n",
       "            <td>M</td>\n",
       "            <td>4000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Maria</td>\n",
       "            <td>Anne</td>\n",
       "            <td>Jones</td>\n",
       "            <td>39192</td>\n",
       "            <td>F</td>\n",
       "            <td>4000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Jen</td>\n",
       "            <td>Mary</td>\n",
       "            <td>Brown</td>\n",
       "            <td></td>\n",
       "            <td>F</td>\n",
       "            <td>-1</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------+------+----------+-------+--------+--------+\n",
       "|      fn |  mid | lastname |    id | gender | salary |\n",
       "+---------+------+----------+-------+--------+--------+\n",
       "|   James |      |    Smith | 36636 |      M |   3000 |\n",
       "| Michael | Rose |          | 40288 |      M |   4000 |\n",
       "|  Robert |      | Williams | 42114 |      M |   4000 |\n",
       "|   Maria | Anne |    Jones | 39192 |      F |   4000 |\n",
       "|     Jen | Mary |    Brown |       |      F |     -1 |\n",
       "+---------+------+----------+-------+--------+--------+"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from demo.default.my_iceberg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5d3ad45-0b31-42de-bf2c-c595baa429d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>col_name</th>\n",
       "            <th>data_type</th>\n",
       "            <th>comment</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>fn</td>\n",
       "            <td>string</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>mid</td>\n",
       "            <td>string</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>lastname</td>\n",
       "            <td>string</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>id</td>\n",
       "            <td>string</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gender</td>\n",
       "            <td>string</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>salary</td>\n",
       "            <td>int</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td># Metadata Columns</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_spec_id</td>\n",
       "            <td>int</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_partition</td>\n",
       "            <td>struct&lt;&gt;</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_file</td>\n",
       "            <td>string</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_pos</td>\n",
       "            <td>bigint</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>_deleted</td>\n",
       "            <td>boolean</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td># Detailed Table Information</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Name</td>\n",
       "            <td>demo.default.my_iceberg</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Type</td>\n",
       "            <td>MANAGED</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Location</td>\n",
       "            <td>s3a://warehouse/user/hive/warehouse/my_iceberg</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Provider</td>\n",
       "            <td>iceberg</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Owner</td>\n",
       "            <td>root</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Table Properties</td>\n",
       "            <td>[current-snapshot-id=4960599606585631684,format=iceberg/parquet,format-version=2,write.parquet.compression-codec=zstd]</td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+------------------------------+------------------------------------------------------------------------------------------------------------------------+---------+\n",
       "|                     col_name |                                                                                                              data_type | comment |\n",
       "+------------------------------+------------------------------------------------------------------------------------------------------------------------+---------+\n",
       "|                           fn |                                                                                                                 string |    None |\n",
       "|                          mid |                                                                                                                 string |    None |\n",
       "|                     lastname |                                                                                                                 string |    None |\n",
       "|                           id |                                                                                                                 string |    None |\n",
       "|                       gender |                                                                                                                 string |    None |\n",
       "|                       salary |                                                                                                                    int |    None |\n",
       "|                              |                                                                                                                        |         |\n",
       "|           # Metadata Columns |                                                                                                                        |         |\n",
       "|                     _spec_id |                                                                                                                    int |         |\n",
       "|                   _partition |                                                                                                               struct<> |         |\n",
       "|                        _file |                                                                                                                 string |         |\n",
       "|                         _pos |                                                                                                                 bigint |         |\n",
       "|                     _deleted |                                                                                                                boolean |         |\n",
       "|                              |                                                                                                                        |         |\n",
       "| # Detailed Table Information |                                                                                                                        |         |\n",
       "|                         Name |                                                                                                demo.default.my_iceberg |         |\n",
       "|                         Type |                                                                                                                MANAGED |         |\n",
       "|                     Location |                                                                         s3a://warehouse/user/hive/warehouse/my_iceberg |         |\n",
       "|                     Provider |                                                                                                                iceberg |         |\n",
       "|                        Owner |                                                                                                                   root |         |\n",
       "|             Table Properties | [current-snapshot-id=4960599606585631684,format=iceberg/parquet,format-version=2,write.parquet.compression-codec=zstd] |         |\n",
       "+------------------------------+------------------------------------------------------------------------------------------------------------------------+---------+"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "describe extended demo.default.my_iceberg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f2062d5-954c-49c7-8d69-98ff0516b8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create database my_iceberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "598750cb-9aed-458e-9c23-b342a3b8e3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| namespace|\n",
      "+----------+\n",
      "|   default|\n",
      "|my_iceberg|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aaf14878-651f-45b6-9a24-1bc547dd5f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create database hello_world_iceberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffd9d7b9-40d6-4215-8792-e8534ba6cf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          namespace|\n",
      "+-------------------+\n",
      "|            default|\n",
      "|hello_world_iceberg|\n",
      "|         my_iceberg|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ffe81dd-057f-4c2b-ad9b-611fba94f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.writeTo(\"hello_world_iceberg.iceberg_test\").createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51c09667-3160-4751-976a-630b4bbc442a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create namespace my_namespace_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93581699-d246-428f-9277-d1cb51c69687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
